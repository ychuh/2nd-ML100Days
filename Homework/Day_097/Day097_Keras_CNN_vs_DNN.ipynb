{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Day097_Keras_CNN_vs_DNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKW1Kup7FMKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkKUg54qFMKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "02991aaf-3807-4337-d63a-75eb7f9dac5f"
      },
      "source": [
        "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
        "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
        "epochs = 50 # 訓練的 epochs 數量\n",
        "lr = 1e-3\n",
        "\n",
        "\n",
        "# 讀取資料並檢視\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhTB-uAAFMKs",
        "colab_type": "text"
      },
      "source": [
        "## 首先我們使用一般的 DNN (MLP) 來訓練\n",
        "由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09gSpuMVFMKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8a689c2-517d-4a90-dd9c-e075852bc647"
      },
      "source": [
        "# 將資料攤平成一維資料\n",
        "x_train = x_train.reshape(50000, 3072) \n",
        "x_test = x_test.reshape(10000, 3072)\n",
        "\n",
        "# 將資料變為 float32 並標準化\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADmobXfIFMKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b9b4a68-dfda-498d-a6d5-48328ee5c321"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_65 (Dense)             (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,841,162\n",
            "Trainable params: 1,841,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 4s 80us/step - loss: 1.9642 - acc: 0.2858 - val_loss: 1.7629 - val_acc: 0.3653\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.8131 - acc: 0.3425 - val_loss: 1.7255 - val_acc: 0.3722\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.7529 - acc: 0.3666 - val_loss: 1.6749 - val_acc: 0.4047\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.7119 - acc: 0.3814 - val_loss: 1.6306 - val_acc: 0.4168\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.6908 - acc: 0.3929 - val_loss: 1.6177 - val_acc: 0.4221\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6618 - acc: 0.4026 - val_loss: 1.5697 - val_acc: 0.4477\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6393 - acc: 0.4105 - val_loss: 1.5574 - val_acc: 0.4500\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6217 - acc: 0.4144 - val_loss: 1.5651 - val_acc: 0.4489\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6096 - acc: 0.4207 - val_loss: 1.5296 - val_acc: 0.4649\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.6015 - acc: 0.4224 - val_loss: 1.5289 - val_acc: 0.4588\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5827 - acc: 0.4308 - val_loss: 1.5075 - val_acc: 0.4647\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5809 - acc: 0.4319 - val_loss: 1.5178 - val_acc: 0.4670\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5656 - acc: 0.4374 - val_loss: 1.5286 - val_acc: 0.4638\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.5635 - acc: 0.4383 - val_loss: 1.4797 - val_acc: 0.4818\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.5510 - acc: 0.4449 - val_loss: 1.4906 - val_acc: 0.4837\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5400 - acc: 0.4459 - val_loss: 1.5106 - val_acc: 0.4707\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5321 - acc: 0.4513 - val_loss: 1.4864 - val_acc: 0.4713\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5236 - acc: 0.4490 - val_loss: 1.4803 - val_acc: 0.4807\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5274 - acc: 0.4521 - val_loss: 1.4692 - val_acc: 0.4871\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.5131 - acc: 0.4576 - val_loss: 1.4705 - val_acc: 0.4896\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5118 - acc: 0.4596 - val_loss: 1.4756 - val_acc: 0.4815\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.5048 - acc: 0.4590 - val_loss: 1.4677 - val_acc: 0.4851\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4994 - acc: 0.4616 - val_loss: 1.4660 - val_acc: 0.4919\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4950 - acc: 0.4622 - val_loss: 1.4348 - val_acc: 0.4993\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4929 - acc: 0.4639 - val_loss: 1.4609 - val_acc: 0.4902\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4846 - acc: 0.4669 - val_loss: 1.4599 - val_acc: 0.4902\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4877 - acc: 0.4662 - val_loss: 1.4583 - val_acc: 0.4880\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4726 - acc: 0.4712 - val_loss: 1.4652 - val_acc: 0.4853\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4670 - acc: 0.4739 - val_loss: 1.4557 - val_acc: 0.4833\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4639 - acc: 0.4758 - val_loss: 1.4803 - val_acc: 0.4781\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4665 - acc: 0.4752 - val_loss: 1.4458 - val_acc: 0.4956\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4622 - acc: 0.4749 - val_loss: 1.4488 - val_acc: 0.4923\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4585 - acc: 0.4769 - val_loss: 1.4495 - val_acc: 0.4887\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4592 - acc: 0.4763 - val_loss: 1.4477 - val_acc: 0.4921\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4505 - acc: 0.4777 - val_loss: 1.4572 - val_acc: 0.4880\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4435 - acc: 0.4821 - val_loss: 1.4440 - val_acc: 0.4838\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4455 - acc: 0.4813 - val_loss: 1.4460 - val_acc: 0.4848\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4462 - acc: 0.4797 - val_loss: 1.4382 - val_acc: 0.4920\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4419 - acc: 0.4822 - val_loss: 1.4459 - val_acc: 0.4822\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4369 - acc: 0.4834 - val_loss: 1.4575 - val_acc: 0.4831\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4336 - acc: 0.4860 - val_loss: 1.4576 - val_acc: 0.4899\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4354 - acc: 0.4866 - val_loss: 1.4356 - val_acc: 0.4921\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 2s 46us/step - loss: 1.4360 - acc: 0.4810 - val_loss: 1.4332 - val_acc: 0.4903\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4318 - acc: 0.4863 - val_loss: 1.4274 - val_acc: 0.4971\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4317 - acc: 0.4856 - val_loss: 1.4393 - val_acc: 0.4965\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4214 - acc: 0.4875 - val_loss: 1.4496 - val_acc: 0.4909\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4221 - acc: 0.4899 - val_loss: 1.4554 - val_acc: 0.4900\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4262 - acc: 0.4883 - val_loss: 1.4256 - val_acc: 0.4975\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4200 - acc: 0.4883 - val_loss: 1.4328 - val_acc: 0.5052\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 2s 45us/step - loss: 1.4109 - acc: 0.4954 - val_loss: 1.4340 - val_acc: 0.4939\n",
            "Test loss: 1.4340309774398803\n",
            "Test accuracy: 0.4939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wehHdvLbFMKx",
        "colab_type": "text"
      },
      "source": [
        "## 接下來我們使用 CNN 來訓練神經網路\n",
        "CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrKQsHoaFMKy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "adccfa13-0460-4d48-c13f-fd88181abbba"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-4mocU4FMK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01ff1cbd-c01a-44d6-f1bf-bfbfcff30093"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_33 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_51 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_54 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 8s 157us/step - loss: 1.6815 - acc: 0.3825 - val_loss: 1.3192 - val_acc: 0.5170\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 1.2798 - acc: 0.5426 - val_loss: 1.0763 - val_acc: 0.6151\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 1.0954 - acc: 0.6098 - val_loss: 0.9775 - val_acc: 0.6607\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.9804 - acc: 0.6534 - val_loss: 0.8838 - val_acc: 0.6873\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.9041 - acc: 0.6799 - val_loss: 0.8213 - val_acc: 0.7131\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.8425 - acc: 0.7044 - val_loss: 0.7794 - val_acc: 0.7308\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.7947 - acc: 0.7205 - val_loss: 0.7669 - val_acc: 0.7309\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.7578 - acc: 0.7351 - val_loss: 0.7058 - val_acc: 0.7549\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.7196 - acc: 0.7481 - val_loss: 0.7031 - val_acc: 0.7520\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.6893 - acc: 0.7576 - val_loss: 0.6647 - val_acc: 0.7699\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.6632 - acc: 0.7655 - val_loss: 0.6611 - val_acc: 0.7718\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.6472 - acc: 0.7742 - val_loss: 0.6774 - val_acc: 0.7633\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.6186 - acc: 0.7812 - val_loss: 0.6503 - val_acc: 0.7781\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5951 - acc: 0.7892 - val_loss: 0.6504 - val_acc: 0.7757\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5827 - acc: 0.7948 - val_loss: 0.6269 - val_acc: 0.7864\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5630 - acc: 0.8006 - val_loss: 0.6097 - val_acc: 0.7902\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5468 - acc: 0.8080 - val_loss: 0.6072 - val_acc: 0.7902\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5388 - acc: 0.8099 - val_loss: 0.6221 - val_acc: 0.7908\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5210 - acc: 0.8144 - val_loss: 0.6054 - val_acc: 0.7943\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5114 - acc: 0.8192 - val_loss: 0.6088 - val_acc: 0.7943\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.5019 - acc: 0.8217 - val_loss: 0.5980 - val_acc: 0.7991\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.4902 - acc: 0.8262 - val_loss: 0.5964 - val_acc: 0.7991\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.4804 - acc: 0.8297 - val_loss: 0.5964 - val_acc: 0.7990\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.4731 - acc: 0.8314 - val_loss: 0.5908 - val_acc: 0.8029\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 6s 119us/step - loss: 0.4625 - acc: 0.8356 - val_loss: 0.5993 - val_acc: 0.7935\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4541 - acc: 0.8389 - val_loss: 0.6041 - val_acc: 0.7986\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4453 - acc: 0.8408 - val_loss: 0.6014 - val_acc: 0.8001\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4414 - acc: 0.8429 - val_loss: 0.6059 - val_acc: 0.7999\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4330 - acc: 0.8450 - val_loss: 0.5857 - val_acc: 0.8017\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4213 - acc: 0.8500 - val_loss: 0.5918 - val_acc: 0.8003\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4207 - acc: 0.8493 - val_loss: 0.6055 - val_acc: 0.7971\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.4089 - acc: 0.8545 - val_loss: 0.5845 - val_acc: 0.8048\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4133 - acc: 0.8528 - val_loss: 0.6254 - val_acc: 0.7971\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.4002 - acc: 0.8567 - val_loss: 0.6134 - val_acc: 0.8019\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3973 - acc: 0.8575 - val_loss: 0.5980 - val_acc: 0.8052\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.3969 - acc: 0.8565 - val_loss: 0.6092 - val_acc: 0.8014\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.3947 - acc: 0.8584 - val_loss: 0.5814 - val_acc: 0.8091\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3756 - acc: 0.8667 - val_loss: 0.6065 - val_acc: 0.8041\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3767 - acc: 0.8661 - val_loss: 0.6070 - val_acc: 0.8008\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3653 - acc: 0.8684 - val_loss: 0.5914 - val_acc: 0.8087\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3682 - acc: 0.8694 - val_loss: 0.6374 - val_acc: 0.7974\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3636 - acc: 0.8712 - val_loss: 0.6088 - val_acc: 0.8073\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3607 - acc: 0.8713 - val_loss: 0.6070 - val_acc: 0.8051\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3496 - acc: 0.8752 - val_loss: 0.6042 - val_acc: 0.8063\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3503 - acc: 0.8763 - val_loss: 0.6062 - val_acc: 0.8085\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3464 - acc: 0.8763 - val_loss: 0.6266 - val_acc: 0.8033\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3398 - acc: 0.8800 - val_loss: 0.5960 - val_acc: 0.8084\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 6s 117us/step - loss: 0.3385 - acc: 0.8782 - val_loss: 0.6200 - val_acc: 0.8056\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.3317 - acc: 0.8839 - val_loss: 0.6234 - val_acc: 0.8028\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 6s 118us/step - loss: 0.3289 - acc: 0.8832 - val_loss: 0.6125 - val_acc: 0.8077\n",
            "Test loss: 0.6124521110534668\n",
            "Test accuracy: 0.8077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXqq1WYNFMK2",
        "colab_type": "text"
      },
      "source": [
        "## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WjIVGLtFMK2",
        "colab_type": "text"
      },
      "source": [
        "## 作業\n",
        "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響? Ans: Increase Epoch can increase accuracy; lower learning rate to 0.001 and batch size around 128 to 256 can improve a lot\n",
        "\n",
        "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪? Ans: DNN參數量較CNN來得多，主要在於CNN將原先input由3027簡化成2304，而第一層input_shape決定了絕大部分的參數數量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxwP8hWgFMK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}